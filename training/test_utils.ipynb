{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sander/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "df = utils.read_json(\"example.json\")\n",
    "df = utils.preprocess(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx, embeds = utils.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.8069,  0.6953, -0.2197,  0.4843, -0.4631, -2.6085,  0.7149,\n",
      "          -0.6537, -2.3779, -1.5479, -4.6900,  1.5900, -5.0653, -4.7665,\n",
      "           3.6805, -4.6223,  3.0753,  2.4923, -1.6052, -3.9231,  1.7908,\n",
      "          -0.6558, -1.9424, -1.6403,  0.0933,  3.6678,  1.5083, -5.6715,\n",
      "           7.1172, -2.1485]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "idx = word_to_idx[\"AITA\"]\n",
    "print(embeds(torch.LongTensor([[idx]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = utils.train_embeddings(df, \"embeddings_30_1000\", 1000)\n",
    "word_to_idx, embeds = utils.gensim_to_pytorch(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4504, -1.2726,  2.4553, -1.1368, -0.3367,  0.4902, -0.0100, -1.3346,\n",
      "         -0.2356, -0.1459, -0.6701,  0.0492, -0.4679, -0.7389, -0.1384, -1.1806,\n",
      "          0.7303,  1.1182,  0.8043,  0.4808, -0.1090, -0.9099,  0.6505,  0.8921,\n",
      "          2.8648, -0.0164,  1.2804, -0.4649, -1.7486,  0.0388]])\n"
     ]
    }
   ],
   "source": [
    "# word_to_idx = {word:index for index, word in enumerate(embeds.wv.index_to_key)}\n",
    "# vectors = torch.[embeds.wv.get_vector(word) for word in embeds.wv.index_to_key]\n",
    "import torch\n",
    "vocab = utils.gen_vocabulary(df, comment=False)\n",
    "print(embeds(torch.LongTensor([1])))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e61c02c6acf22417c29e8a70dda14ceeb759185a4fdfa7262e09386a5c3ea102"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('AI-Judge': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
