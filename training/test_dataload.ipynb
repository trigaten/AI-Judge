{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eca750a-23f7-4d4b-a47d-2e682c922f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import utils\n",
    "import pandas as pd\n",
    "import AITA_Dataset\n",
    "import torchtext as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9419bf-a9e3-4574-ad04-a052eb40519b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_body</th>\n",
       "      <th>judgement</th>\n",
       "      <th>comment_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aita, for, giving, my, group, member, a, bad,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[yta, she, contributed, to, the, project, (, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[aita, for, agreeing, to, date, my, so, just, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[esh, but, holy, shit, this, is, a, terrible, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[aita, for, holding, the, wrist, of, a, 13, ye...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nta, ., your, wife, is, the, asshole, here, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[aita, for, snapping, at, my, boyfriend, in, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nta, ., you, tried, to, tell, himcalmly, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[aita, for, calling, out, my, mother, ?, to, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nta, your, mom, should, pick, up, that, bible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>[aita, for, wanting, to, get, my, ex, fired, ?...</td>\n",
       "      <td>1</td>\n",
       "      <td>[esh, ., your, ex, sounds, like, a, massive, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>[aita-, my, puppy, ate, a, drunk, girls, shoes...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nta, ., she, should, have, looked, for, her, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>[wibta, if, ask, my, dead, dad, 's, sisters, i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nta, ., you, ’, re, a, parent, now, -, would,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>[aita, for, expecting, to, share, finances, -,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, ., different, couples, handle, money, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[aita, for, not, wanting, to, attend, my, frie...</td>\n",
       "      <td>1</td>\n",
       "      <td>[yta, ,, not, for, not, wanting, to, attend, ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_body  judgement  \\\n",
       "0    [aita, for, giving, my, group, member, a, bad,...          1   \n",
       "1    [aita, for, agreeing, to, date, my, so, just, ...          1   \n",
       "2    [aita, for, holding, the, wrist, of, a, 13, ye...          0   \n",
       "3    [aita, for, snapping, at, my, boyfriend, in, f...          0   \n",
       "4    [aita, for, calling, out, my, mother, ?, to, p...          0   \n",
       "..                                                 ...        ...   \n",
       "392  [aita, for, wanting, to, get, my, ex, fired, ?...          1   \n",
       "393  [aita-, my, puppy, ate, a, drunk, girls, shoes...          0   \n",
       "394  [wibta, if, ask, my, dead, dad, 's, sisters, i...          0   \n",
       "395  [aita, for, expecting, to, share, finances, -,...          0   \n",
       "396  [aita, for, not, wanting, to, attend, my, frie...          1   \n",
       "\n",
       "                                          comment_body  \n",
       "0    [yta, she, contributed, to, the, project, (, m...  \n",
       "1    [esh, but, holy, shit, this, is, a, terrible, ...  \n",
       "2    [nta, ., your, wife, is, the, asshole, here, ,...  \n",
       "3    [nta, ., you, tried, to, tell, himcalmly, and,...  \n",
       "4    [nta, your, mom, should, pick, up, that, bible...  \n",
       "..                                                 ...  \n",
       "392  [esh, ., your, ex, sounds, like, a, massive, p...  \n",
       "393  [nta, ., she, should, have, looked, for, her, ...  \n",
       "394  [nta, ., you, ’, re, a, parent, now, -, would,...  \n",
       "395  [nah, ., different, couples, handle, money, di...  \n",
       "396  [yta, ,, not, for, not, wanting, to, attend, ,...  \n",
       "\n",
       "[397 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.read_json('example.json')\n",
    "df = utils.preprocess(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7380f2b0-105f-418a-aa3f-6662756f8985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke Luo\\git\\AI-Judge\\training\\utils.py:117: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  weights = torch.FloatTensor([gse.wv.get_vector(word) for word in gse.wv.index_to_key])\n"
     ]
    }
   ],
   "source": [
    "vocab = utils.gen_vocabulary(df, comment=False)\n",
    "embeds = utils.train_embeddings(df, \"embeddings_30_1000\", 1000)\n",
    "word_to_idx, embeds = utils.gensim_to_pytorch(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034d0e16-2b4b-4441-8a70-beb46a0c3a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AITA_Dataset.AITA_Dataset at 0x20f4eac5340>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = AITA_Dataset.AITA_Dataset(df, word_to_idx)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7190e52-7e5b-4db0-9e25-218d13543a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mycollator(batch):\n",
    "    print(batch[0][1])\n",
    "    return {\n",
    "        (x[0] for x in batch),\n",
    "        (x[1] for x in batch)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aad0047-868d-48d4-9a07-808e919ea2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils' has no attribute 'UNKOWN_TOKEN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUKELU~1\\AppData\\Local\\Temp/ipykernel_19280/642333490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAITA_Dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_to_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\judge\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\judge\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\judge\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\judge\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\AI-Judge\\training\\AITA_Dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# print(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_special_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_special_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_special_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\AI-Judge\\training\\AITA_Dataset.py\u001b[0m in \u001b[0;36mapply_special_tokens\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0msentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"<UNK>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART_TOKEN\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_TOKEN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'utils' has no attribute 'UNKOWN_TOKEN'"
     ]
    }
   ],
   "source": [
    "loader = AITA_Dataset.get_dataloader(df, word_to_idx)\n",
    "features, labels = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1e976ba-7d52-45c6-a282-960b5d1e39cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object mycollator.<locals>.<genexpr> at 0x000001C8D78C6820>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138ac1fd-2ab1-4167-8988-f3d7a6116679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUKELU~1\\AppData\\Local\\Temp/ipykernel_31204/2444071596.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  batch = batch.drop(0, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_body</th>\n",
       "      <th>comment_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&lt;BEG&gt;, &lt;UNK&gt;, -, kinda, ..., but, that, fit, ...</td>\n",
       "      <td>[&lt;BEG&gt;, aita, for, wanting, &lt;UNK&gt;, my, fiance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[&lt;BEG&gt;, nta, ., in, fact, i, believe, that, 's...</td>\n",
       "      <td>[&lt;BEG&gt;, aita, for, insisting, my, wife, get, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[&lt;BEG&gt;, nta, i, think, financially, supporting...</td>\n",
       "      <td>[&lt;BEG&gt;, aita, for, not, ``, supporting, the, &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[&lt;BEG&gt;, &lt;UNK&gt;, ., i, love, movies, and, enjoy,...</td>\n",
       "      <td>[&lt;BEG&gt;, aita, for, getting, pissed, off, if, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_body  \\\n",
       "1  [<BEG>, <UNK>, -, kinda, ..., but, that, fit, ...   \n",
       "2  [<BEG>, nta, ., in, fact, i, believe, that, 's...   \n",
       "3  [<BEG>, nta, i, think, financially, supporting...   \n",
       "4  [<BEG>, <UNK>, ., i, love, movies, and, enjoy,...   \n",
       "\n",
       "                                        comment_body  \n",
       "1  [<BEG>, aita, for, wanting, <UNK>, my, fiance,...  \n",
       "2  [<BEG>, aita, for, insisting, my, wife, get, r...  \n",
       "3  [<BEG>, aita, for, not, ``, supporting, the, <...  \n",
       "4  [<BEG>, aita, for, getting, pissed, off, if, b...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = pd.DataFrame([features, labels], ['post_body', 'comment_body'])\n",
    "batch = batch.drop(0, 1)\n",
    "batch = batch.transpose()\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b708d1-4227-48ed-be94-64aafa57ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BEG>', 'nta', '-', '<UNK>', 'isn', '’', 't', 'doing', 'that', 'kid', 'any', '<UNK>', '.', 'maybe', 'a', 'little', '<UNK>', 'for', 'the', '<UNK>', '(', 'i', 'mean', ',', '<UNK>', ',', 'was', 'it', 'really', '<UNK>', 'bad', '?', ')', 'life', 'is', 'tough', 'and', 'everyone', 'has', 'a', 'story', ',', 'that', 'doesn', '’', 't', 'make', 'you', 'the', 'asshole', 'for', 'being', 'honest', 'in', 'a', 'competition', 'where', 'you', 'were', 'asked', 'to', 'be', 'honest', '.', '<END>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUKELU~1\\AppData\\Local\\Temp/ipykernel_31204/1719168998.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  post = post.drop(0, 1)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = enumerate(next(iter(loader)))\n",
    "post = pd.DataFrame([train_features, train_labels], ['post_body', 'comment_body'])\n",
    "post = post.drop(0, 1)\n",
    "post = post.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bab9e8-a67e-4252-9c9f-c577362b3011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e61c02c6acf22417c29e8a70dda14ceeb759185a4fdfa7262e09386a5c3ea102"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('AI-Judge': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
