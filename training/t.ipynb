{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from utils import END_TOKEN, UNKNOWN_TOKEN\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, post_embeddings, comment_embeddings, device):\n",
    "        super().__init__()\n",
    "        self.post_embeddings = post_embeddings\n",
    "        self.comment_embeddings = comment_embeddings\n",
    "        self.encoder = Encoder(self.post_embeddings)\n",
    "        self.decoder = Decoder(self.comment_embeddings)\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, encoded_post_body, encoded_target_comment, tf_ratio=0.5):\n",
    "        embedded = self.post_embeddings(encoded_post_body)\n",
    "        out, context = self.encoder(embedded)\n",
    "        \n",
    "        return context\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, post_embeddings):\n",
    "        super().__init__()\n",
    "        self.post_embeddings = post_embeddings\n",
    "        self.encoder = nn.GRU(30, 1200, 3, batch_first=True, bidirectional=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.post_embedding(x)\n",
    "        # push vector through encoder\n",
    "        # then take just the hidden vectors as the context vectors\n",
    "        out, h_n = self.encoder(embedded)\n",
    "\n",
    "        return h_n\n",
    "\n",
    "# only for proof of concept-- cant work with batches\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, comment_embeddings):\n",
    "        super().__init__()\n",
    "        self.comment_embeddings = comment_embeddings\n",
    "        self.decoder = nn.GRU(30, 1200, 3, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(1200, comment_embeddings.num_embeddings)\n",
    "\n",
    "    def forward(self, context, last_output_word):\n",
    "        \"\"\"\n",
    "        Since this function gets called once at a time rather than taking in\n",
    "        a sequence of vectors, we need to pass it the last output. This will be just\n",
    "        a vector of numbers that can be converted to the embedding representing that last output\n",
    "        \"\"\"\n",
    "        embedded = self.comment_embeddings(last_output_word)\n",
    "        out, h_n = self.decoder(context, embedded)\n",
    "\n",
    "        return h_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sander/AI-Judge/training/utils.py:117: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1634272478997/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  weights = torch.FloatTensor([gse.wv.get_vector(word) for word in gse.wv.index_to_key])\n"
     ]
    }
   ],
   "source": [
    "post_word_to_idx, post_embeddings = utils.get_embeddings(\"post_embeddings_W2V_30_1000\")\n",
    "comment_word_to_idx, comment_embeddings = utils.get_embeddings(\"comment_embeddings_W2V_30_1000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = utils.read_json(\"example.json\")\n",
    "df = utils.preprocess(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = seq2seq(post_embeddings, comment_embeddings, \"cpu\")\n",
    "# Decoder(comment_embeddings)\n",
    "# comment_embeddings.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(torch.LongTensor([[1,2]]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 258, 30])\n",
      "tensor([[[ 0.0045, -0.0141, -0.0066,  ..., -0.0049, -0.0082, -0.0111],\n",
      "         [-0.0032, -0.0130, -0.0112,  ..., -0.0062, -0.0115, -0.0153],\n",
      "         [ 0.0050, -0.0119, -0.0173,  ...,  0.0010, -0.0089, -0.0127],\n",
      "         ...,\n",
      "         [ 0.0468, -0.0095, -0.0345,  ...,  0.0194,  0.0504, -0.0430],\n",
      "         [ 0.0382, -0.0046, -0.0411,  ...,  0.0134,  0.0509, -0.0429],\n",
      "         [ 0.0283, -0.0049, -0.0542,  ...,  0.0088,  0.0707, -0.0401]],\n",
      "\n",
      "        [[ 0.0045, -0.0141, -0.0066,  ..., -0.0049, -0.0082, -0.0111],\n",
      "         [-0.0032, -0.0130, -0.0112,  ..., -0.0062, -0.0115, -0.0153],\n",
      "         [ 0.0050, -0.0119, -0.0173,  ...,  0.0010, -0.0089, -0.0127],\n",
      "         ...,\n",
      "         [ 0.0468, -0.0095, -0.0345,  ...,  0.0194,  0.0504, -0.0430],\n",
      "         [ 0.0382, -0.0046, -0.0411,  ...,  0.0134,  0.0509, -0.0429],\n",
      "         [ 0.0283, -0.0049, -0.0542,  ...,  0.0088,  0.0707, -0.0401]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "____+_\n",
      "tensor([[[-0.0676, -0.3967, -0.1826,  ..., -0.1448, -0.0939, -0.1520],\n",
      "         [-0.0676, -0.3967, -0.1826,  ..., -0.1448, -0.0939, -0.1520]],\n",
      "\n",
      "        [[ 0.0470, -0.0354,  0.0746,  ...,  0.0538, -0.0655,  0.1847],\n",
      "         [ 0.0470, -0.0354,  0.0746,  ...,  0.0538, -0.0655,  0.1847]],\n",
      "\n",
      "        [[ 0.0283, -0.0049, -0.0542,  ...,  0.0088,  0.0707, -0.0401],\n",
      "         [ 0.0283, -0.0049, -0.0542,  ...,  0.0088,  0.0707, -0.0401]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0045, -0.0141, -0.0066,  ..., -0.0049, -0.0082, -0.0111],\n",
       "         [-0.0032, -0.0130, -0.0112,  ..., -0.0062, -0.0115, -0.0153],\n",
       "         [ 0.0050, -0.0119, -0.0173,  ...,  0.0010, -0.0089, -0.0127],\n",
       "         ...,\n",
       "         [ 0.0468, -0.0095, -0.0345,  ...,  0.0194,  0.0504, -0.0430],\n",
       "         [ 0.0382, -0.0046, -0.0411,  ...,  0.0134,  0.0509, -0.0429],\n",
       "         [ 0.0283, -0.0049, -0.0542,  ...,  0.0088,  0.0707, -0.0401]],\n",
       "\n",
       "        [[ 0.0045, -0.0141, -0.0066,  ..., -0.0049, -0.0082, -0.0111],\n",
       "         [-0.0032, -0.0130, -0.0112,  ..., -0.0062, -0.0115, -0.0153],\n",
       "         [ 0.0050, -0.0119, -0.0173,  ...,  0.0010, -0.0089, -0.0127],\n",
       "         ...,\n",
       "         [ 0.0468, -0.0095, -0.0345,  ...,  0.0194,  0.0504, -0.0430],\n",
       "         [ 0.0382, -0.0046, -0.0411,  ...,  0.0134,  0.0509, -0.0429],\n",
       "         [ 0.0283, -0.0049, -0.0542,  ...,  0.0088,  0.0707, -0.0401]]],\n",
       "       grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.iloc[31][\"post_body\"]\n",
    "data = [post_word_to_idx[word] if word in post_word_to_idx else post_word_to_idx[UNKNOWN_TOKEN] for word in data]\n",
    "data = torch.LongTensor([data, data])\n",
    "# emb = post_embeddings(data)\n",
    "# print(emb.shape)\n",
    "# m(data)\n",
    "n = nn.GRU(30, 1200, 3, batch_first=True, bidirectional=False)\n",
    "m(data)\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 30])\n"
     ]
    }
   ],
   "source": [
    "print(d.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e61c02c6acf22417c29e8a70dda14ceeb759185a4fdfa7262e09386a5c3ea102"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('AI-Judge': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
