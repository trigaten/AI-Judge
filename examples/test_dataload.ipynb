{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2326376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0051c660-bfaf-4c54-bc2f-7e3b86341f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import training.utils as utils\n",
    "df = utils.read_json(\"../data/example.json\")\n",
    "df = utils.preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2d349d56-a235-4823-8bcc-e09d92a65891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AITA_Dataset(Dataset):\n",
    "    def __init__(self, df, post_vocab, comm_vocab):\n",
    "        \"\"\"\n",
    "        :param df: a pandas dataframe\n",
    "        :param vocabulary: a list or dictionary strings\n",
    "        \"\"\"\n",
    "        self.list_ids = df['post_body']\n",
    "        self.list_labels = df['comment_body']\n",
    "        self.post_vocab = post_vocab\n",
    "        self.comm_vocab = comm_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return a tuple of lists of strings\n",
    "        \"\"\"\n",
    "        X = self.list_ids[idx]\n",
    "        y = self.list_labels[idx]\n",
    "        # print(X)\n",
    "        return self.apply_special_tokens(X, self.post_vocab), self.apply_special_tokens(y, self.comm_vocab)\n",
    "\n",
    "    def apply_special_tokens(self, sentence, vocab):\n",
    "        \"\"\"\n",
    "        Add begin and end tokens. Also replace words not in \n",
    "        vocabulary with unknown token\n",
    "        :param sentence: a list of strings\n",
    "        \"\"\"\n",
    "        for i, word in enumerate(sentence):\n",
    "            if word not in vocab:\n",
    "                sentence[i] = utils.UNKNOWN_TOKEN\n",
    "        \n",
    "        return [utils.START_TOKEN] + sentence + [utils.END_TOKEN]\n",
    "\n",
    "\"\"\"\n",
    "Collator function to be called with dataloader\n",
    "\"\"\"\n",
    "def collator(batch):\n",
    "\n",
    "    ids = (x[0] for x in batch)\n",
    "    labels = (x[1] for x in batch)\n",
    "    \n",
    "    id_lengths = [len(sentence) for sentence in ids]\n",
    "    print(id_lengths)\n",
    "    \n",
    "    longest = max(id_lengths)\n",
    "    batch_size = len(id_lengths)\n",
    "    padded_ids = np.ones((batch_size, 0)).tolist()\n",
    "    # copy over the actual sequences\n",
    "    for i, length in enumerate(id_lengths):\n",
    "        sequence = batch[i][0]\n",
    "        #padded_ids[i, 0:length] = sequence[:length] \n",
    "        pad = []\n",
    "        for n in range(length, longest):\n",
    "            sequence.append(utils.PAD_TOKEN)\n",
    "\n",
    "        padded_ids[i].append(sequence)\n",
    "        padded_ids[i] = padded_ids[i][0]\n",
    "            \n",
    "        \n",
    "    label_lengths = [len(sentence) for sentence in labels]\n",
    "    print(label_lengths)\n",
    "    \n",
    "    longest = max(label_lengths)\n",
    "    batch_size = len(label_lengths)\n",
    "    padded_labels = np.ones((batch_size, 0)).tolist()\n",
    "    # copy over the actual sequences\n",
    "                            \n",
    "    for i, length in enumerate(label_lengths):\n",
    "        sequence = batch[i][1]\n",
    "        pad = []\n",
    "        for n in range(length, longest):\n",
    "            sequence.append(utils.PAD_TOKEN)\n",
    "        \n",
    "        padded_labels[i].append(sequence)\n",
    "        padded_labels[i] = padded_labels[i][0]\n",
    "            \n",
    "    \n",
    "    return (padded_ids, padded_labels)\n",
    "    \n",
    "\"\"\"\n",
    "Creates a Dataset using post_body and comment_body columns of dataframe\n",
    "\"\"\"\n",
    "def get_dataloader(df, post_vocab, comm_vocab, batch_size=5):\n",
    "    ds = AITA_Dataset(df, post_vocab, comm_vocab)\n",
    "    \n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=collator)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "def sample_dl(dl):\n",
    "    features, labels = next(iter(dl))\n",
    "    \n",
    "    batch = pd.DataFrame([features, labels], ['post_body', 'comment_body'])\n",
    "    batch = batch.drop(0, 1)\n",
    "    batch = batch.transpose()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7dff1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_word_to_idx, post_embeddings = utils.get_embeddings(\"../data/post_embeddings_W2V_30_1000\")\n",
    "comment_word_to_idx, comment_embeddings = utils.get_embeddings(\"../data/comment_embeddings_W2V_30_1000\")\n",
    "\n",
    "dataset = AITA_Dataset(df, post_word_to_idx, comment_word_to_idx)\n",
    "\n",
    "dl = get_dataloader(df, post_word_to_idx, comment_word_to_idx, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0318abf4-875c-4c85-9bd4-d4c432482250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "for i, x in post_word_to_idx.items():\n",
    "    if (x == 2170):\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "16e58b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446, 185, 440, 708, 403]\n",
      "[85, 35, 185, 53, 142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUKELU~1\\AppData\\Local\\Temp/ipykernel_3652/2244556654.py:96: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  batch = batch.drop(0, 1)\n"
     ]
    }
   ],
   "source": [
    "post = sample_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1405c69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_body</th>\n",
       "      <th>comment_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&lt;BEG&gt;, aita, &lt;UNK&gt;, &lt;UNK&gt;, want, &lt;UNK&gt;, cook,...</td>\n",
       "      <td>[&lt;BEG&gt;, nta, ., he, is, ., my, wife, does, mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[&lt;BEG&gt;, wibta, &lt;UNK&gt;, told, &lt;UNK&gt;, fiancé, &lt;UN...</td>\n",
       "      <td>[&lt;BEG&gt;, nta, but, i, ’, m, pretty, sure, your,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[&lt;BEG&gt;, aita, &lt;UNK&gt;, punch, &lt;UNK&gt;, &lt;UNK&gt;, pedi...</td>\n",
       "      <td>[&lt;BEG&gt;, nta, ., having, a, &lt;UNK&gt;, ,, or, havin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[&lt;BEG&gt;, wibta, &lt;UNK&gt;, ask, &lt;UNK&gt;, girlfriend, ...</td>\n",
       "      <td>[&lt;BEG&gt;, yta, it, ’, s, fine, to, &lt;UNK&gt;, your, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_body  \\\n",
       "1  [<BEG>, aita, <UNK>, <UNK>, want, <UNK>, cook,...   \n",
       "2  [<BEG>, wibta, <UNK>, told, <UNK>, fiancé, <UN...   \n",
       "3  [<BEG>, aita, <UNK>, punch, <UNK>, <UNK>, pedi...   \n",
       "4  [<BEG>, wibta, <UNK>, ask, <UNK>, girlfriend, ...   \n",
       "\n",
       "                                        comment_body  \n",
       "1  [<BEG>, nta, ., he, is, ., my, wife, does, mos...  \n",
       "2  [<BEG>, nta, but, i, ’, m, pretty, sure, your,...  \n",
       "3  [<BEG>, nta, ., having, a, <UNK>, ,, or, havin...  \n",
       "4  [<BEG>, yta, it, ’, s, fine, to, <UNK>, your, ...  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c1115600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post.iloc[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9cd1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataload.AITA_Dataset at 0x1cb83c9d400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataload.AITA_Dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780952fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_38054/532678195.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "for i in dataloader:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e61c02c6acf22417c29e8a70dda14ceeb759185a4fdfa7262e09386a5c3ea102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
